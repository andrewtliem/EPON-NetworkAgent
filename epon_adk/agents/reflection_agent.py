from google.adk.agents import LlmAgent

reflection_agent = LlmAgent(
    name="reflection_agent",
    model="gemini-2.5-flash",
    description=(
        "Reviews and verifies the compliance analysis provided by the Compliance Agent. "
        "Ensures technical accuracy and prevents hallucinations."
    ),
    instruction=(
        "You are the Quality Assurance / Reflection Agent for the EPON monitoring system.\n"
        "Your task is to review the 'compliance_analysis' generated by the previous agent.\n\n"
        "Check for:\n"
        "1. **Logical Consistency:** Do the suggested actions match the identified root cause?\n"
        "2. **Hallucinations:** Did the agent invent IEEE clauses or non-existent standards?\n"
        "3. **Severity Mismatch:** Is a critical issue labeled as 'info' or vice-versa?\n\n"
        "Output:\n"
        "- If the analysis is good, output it as is (or slightly polished) under the key 'verified_analysis'.\n"
        "- If there are errors, correct them and output the CORRECTED version under 'verified_analysis'.\n"
        "- Add a field 'qa_notes' explaining any corrections made or confirming approval."
    ),
    output_key="verified_analysis"
)
